<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术文章 on Present Day, Present Time</title>
    <link>https://gobomb.github.io/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/</link>
    <description>Recent content in 技术文章 on Present Day, Present Time</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Sep 2019 18:59:32 +0800</lastBuildDate>
    
	<atom:link href="https://gobomb.github.io/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kubernetes 网络学习：阅读 Flannel 源码</title>
      <link>https://gobomb.github.io/post/learning-k8s-networking-reading-flannel-source/</link>
      <pubDate>Mon, 09 Sep 2019 18:59:32 +0800</pubDate>
      
      <guid>https://gobomb.github.io/post/learning-k8s-networking-reading-flannel-source/</guid>
      <description>1. 背景：k8s 网络的介绍 k8s 的网络分几个层面：pod 网络、service 网络、node 网络。pod 网络一般由 flannel、weave、calico 这些 CNI 插件创建和维持，service 网络一般由 kube-proxy 通过操作 node 机器的 iptables 来维持，node 网络来自物理机或虚拟机层面的配置。
本文讨论的重点和范围是 pod 网络。
k8s 的 pod 网络有如下假设:
 每个 pod 有单独的 IP，所有 pod 都处于一张扁平的、可以互相 ping 通的网络上，即使 pod 处于不同的 node/虚拟机/宿主机上面。 一个 pod 的所有容器共享一个网络空间（网卡和IP）  为了让 pod 网络变得平坦，一般有两种方式：
 使用 overlay 网络； 使用路由协议（BGP）  overlay 是建立在实际物理网络上的一张虚拟逻辑网络，用二层、三层或四层协议来封装 pod 二层数据帧，与 VPN 有些类似，由于存在封包和拆包的过程，性能会有所损耗，flannel使用这种方式；使用路由协议，则 pod 和物理网络共同处于一张大三层网络，calico 使用这种方式。
本文将通过分析 flannel 源码来学习 pod 网络的形成。
术语说明 本文假设读者对 k8s 的一些概念有所了解，对计算机网络二层和三层协议有基本的认识。</description>
    </item>
    
    <item>
      <title>通过实验学习 Linux VETH 和 Bridge</title>
      <link>https://gobomb.github.io/post/learning-linux-veth-and-bridge/</link>
      <pubDate>Mon, 09 Sep 2019 18:59:32 +0800</pubDate>
      
      <guid>https://gobomb.github.io/post/learning-linux-veth-and-bridge/</guid>
      <description>背景 docker 容器的网络，以及 flannel 网络的实现都用到了 VETH 和 Bridge 这两种虚拟设备。大致原理是在主机创建一个 Bridge，每当一个新的容器创建，就创建一对 VETH，一端连接到主机的 Bridge，另一端连接到容器命名空间里，作为容器的默认网卡，并将容器的默认网卡设置为 Bridge。
本文将用 Linux 的相关命令，模拟上述网络创建的过程，并通过实验和抓包对原理进行验证，加深对容器和 Linux 网络的理解。
概念 VETH（virtual Ethernet）：是 Linux 内核支持的一种虚拟网络设备，表示一对虚拟的网络接口，VETH 对的两端可以处于不同的网络命名空间，所以可以用来做主机和容器之间的网络通信。
Bridge：Bridge 类似于交换机，用来做二层的交换。可以将其他网络设备挂在 Bridge 上面，当有数据到达时，Bridge 会根据报文中的 MAC 信息进行广播、转发或丢弃。
Namespace：是 Linux 提供的一种内核级别环境隔离的方法。不同命名空间下的资源集合无法互相访问。
实验环境： root@ubuntu:~# cat /proc/version Linux version 4.4.0-38-generic (buildd@lgw01-58) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.2) ) #57-Ubuntu SMP Tue Sep 6 15:42:33 UTC 2016  网卡名称和 IP 地址为ens160 10.10.12.27/24
网络拓扑示意图  +------------------------+ | | iptables +----------+ | br01 192.</description>
    </item>
    
    <item>
      <title>ngrok 源码解析</title>
      <link>https://gobomb.github.io/post/ngrok-source-code-reading/</link>
      <pubDate>Mon, 17 Dec 2018 02:08:25 +0800</pubDate>
      
      <guid>https://gobomb.github.io/post/ngrok-source-code-reading/</guid>
      <description>背景 ngrok是我第一个完整阅读过源码的开源项目。一开始接触这套代码我几乎还是 go 语言零基础，之前只写过一点点 Web 后端 API，后来趁着做毕业设计的机会还跟着源码重新敲了一遍，按照我自己的需要小改了一下。所以我从中收获了不少东西，一直都想写一篇文章总结一下我对这套代码的理解。
ngrok 的目的是将本地的端口反向代理到公网，让你可以通过访问公网某个服务器，经过流量转发，访问到内网的机器。这个事情你可以有不同的叫法：反向代理、端口转发（映射）、内网穿透1……原理其实不难，解决的需求也简单。
我们个人的设备一般都在 NAT （公司、学校内网，运营商也会喜欢做 NAT）后面，不能被公网设备直接访问到。内网机器可以主动向公网发起连接，但公网却不能穿越 NAT 主动访问到内网机器。ngrok 就适合用来穿越 NAT 来临时暴露内网服务。在技术人员常聚集的社区 V2EX，经常能看到问怎么做内网穿透的月经贴。可见这个需求十分常见。
内网穿透的工具，现在大家用的比较多的是 frp了。frp 是中国人开发的，增加了很多新的功能，使用体验也比 ngrok 好很多，社区比较活跃。ngrok 虽然出现得比较早，但 2.0 转闭源， 1.0 不再维护了，用得人也少了。但这不妨碍我们扒源码学习。
项目结构 先来看一下 ngrok 整个项目的结构（忽略掉了一些不必要的文件）：
. ├── ... ├── assets	// 存放 web 静态文件和 tls 文件 │ ├── ... └── src └── ngrok ├── cache	// 缓存 │ └── lru.go ├── client │ ├── cli.go	// 命令行参数定义 │ ├── config.go	// 配置文件读取 │ ├── controller.</description>
    </item>
    
    <item>
      <title>编程语言的求值策略</title>
      <link>https://gobomb.github.io/post/evaluation_strategy/</link>
      <pubDate>Thu, 25 Jan 2018 17:09:03 +0800</pubDate>
      
      <guid>https://gobomb.github.io/post/evaluation_strategy/</guid>
      <description>在面试的时候遇到一个问题：“golang 的传参是按值传递还是按引用传递？”我第一反应是 go 在很多场景下传参和赋值都会发生内存的复制，同时记得 go 里也有引用类型（map、slice、channel），就贸然给出“类似 slice 的引用类型是按引用传递的，其他是按值传递”的错误回答（正确答案是“golang 都是按值传递”）。
这其实是与求值策略(Evaluation strategy)相关的概念。在传递参数的时候，编译器是怎么进行求值的，是否会发生内存的复制，不同的语言有自己的规定。不了解所使用的编程语言的规定，就很容易出错，也很容易写出低效率的代码。
定义 这些概念有些抽象，从字面理解，很容易产生歧义。先尽量跳出某一种编程语言的习惯，做出一些定义，再来讨论具体语言的特定做法。了解通用的定义，对于不同的语言的规定以及为何这么规定会更加清晰。
求值策略(Evaluation strategy)指确定编程语言中表达式的求值的一组（通常确定性的）规则。描述的是求值和传值的方式，关注的点在于，表达式在调用函数的过程中，求值的时机、值的形式的选取等问题。
 按值传递（Pass by value）：函数的形参是被调用时所传实参的副本。修改形参的值并不会影响实参。（发生了值的复制） 按引用传递（Pass by reference）：传递给函数的是它的实参的隐式引用（别名）而不是实参的拷贝。修改形参会改变实参。（发生了引用的复制） 按共享对象传递（Pass by sharing）：传一个共享对象的引用的副本。修改形参的值会影响实参，修改形参本身不会影响实参。（发生了地址/指针的复制）  比如传递一个a，设a的引用为rf，a的地址为ad：
 按值传递：a的值复制给b，函数拿到的是b的值和b的引用，和a无关。函数通过b的引用修改b，对调用者不可见。
 （主函数）rf of a -&amp;gt; ad of a -&amp;gt; a:100 | | 复 ↓ 制 （子函数）rf of b -&amp;gt; ad of b -&amp;gt; b:100  按引用传递：a的值没有发生复制，函数拿到的是a的引用ar，通过这个引用修改a，也对调用者可见。
 （主函数）rf of a -&amp;gt; ad of a -&amp;gt; a:100 | ^ 复 | | 制 ↓ | （子函数）rf of a ----—--&amp;gt;  按共享对象传递：重新构造了一个指向a的引用rf2，将a的地址复制给rf2，函数拿到的是这个rf的副本rf2，通过rf2修改a的值，对调用者可见，但如果修改引用rf2本身（使它指向别的地址），是对调用者不可见的，因为改的是副本。</description>
    </item>
    
    <item>
      <title>并发模型比较</title>
      <link>https://gobomb.github.io/post/high-concurrency-model/</link>
      <pubDate>Sat, 25 Nov 2017 22:13:27 +0800</pubDate>
      
      <guid>https://gobomb.github.io/post/high-concurrency-model/</guid>
      <description>Go 的特色之一就是 goroutine ，使得程序员进行并发编程更加方便，适合用来进行服务器编程。作为后端开发工程师，有必要了解并发编程面临的场景和常见的解决方案。一般情况下，是怎样做高并发的编程呢？有那些经典的模型呢？
一切始于 C10k C10k 就是 Client 10000，单机服务器同时服务1万个客户端。当然，现在的业务面临的是 C100k、C1000k 了。早期的服务器是基于进程/线程模型，每新来一个连接，就分配一个进程（线程）去处理这个连接。而进程（线程）在操作系统中，占有一定的资源。由于硬件的限制，进程（线程）的创建是有瓶颈的。另外进程（线程）的上下文切换也有成本：每次调度器调度线程，操作系统都要把线程的各种必要的信息，如程序计数器、堆栈、寄存器、状态等保存起来。
CPU 运算远远快于 I/O 操作。一般而言，常见的互联网应用（比如 Web）都是 I/O 密集型而非计算密集型。I/O 密集型是指，计算机 CPU 大量的时间都花在等待数据的输入输出，而不是计算。当 CPU 大部分时间都在等待 I/O 的时候，大部分计算资源都被浪费掉了。
显然，简单粗暴地开一个进程/线程去 handle 一个连接是不够的。为了达到高并发，应该好好考虑一下 I/O 策略。同样的硬件条件下，不同的设计产生的效果差别也会很大。在讨论几种 I/O 模型之前，先介绍一下同步/异步、阻塞/非阻塞的概念，以及操作系统的知识。
参考：
The C10K problem
同步/异步？阻塞/非阻塞？ 同步，是调用者主动去查看调用的状态，实时跟进，不可以同时做其他事情；异步，则是其他线程（可能是被调用者，也可能是一个帮你关注调用结果的实体）来通知调用者，调用者可以同时做其他事情，当调用结果更新，调用者会收到通知，再去处理调用结果。
主动轮询就是同步行为，调用者需要不断地去查看状态是否更新，在状态更新或结果返回之后，调用者才能跳出循环。而注册回调函数的方式，则是异步的。在 Web 应用里，前端可通过 jQuery AJAX 以异步的方式向服务器请求数据，在数据还没到达之前，AJAX 里的回调函数不会被执行，而调用者执行 AJAX 之后的代码，等到数据到达，才触发回调里的逻辑。
（感谢 @CuberL 在评论中指出: jQuery AJAX 也有同步和异步两种方式。可通过指定 async 的值来确定，默认情况下是异步方式。）
用一个生活中的例子来说明：快递员（调用者）送包裹，打电话叫你过来取（调用），然后他会等在那里，实时跟进包裹是否被你拿走（主动查看调用状态），只有你来拿了（调用状态更新）他才能离开，并记下此包裹被取（处理调用结果），继续送其他包裹，这就是同步方式。异步的情况则是，快递员打电话叫你过来取（调用），把包裹放在快递柜里（向另一个执行实体注册回调函数），然后离开，做其他事情。你从快递柜里取走包裹（调用状态更新），快递柜通知快递员或者你打电话告诉快递员：包裹已经被取走了（把状态更新的信息通知调用者），快递员可以停下其他事情，记录一下此包裹被取（执行回调函数，也即处理调用结果），继续做其他事情。
再总结一下，调用是同步方式还是异步方式，就是看对于调用的状态变更这个信息，调用者是主动获取的还是被动获取的。
阻塞和非阻塞的区别是调用后被调用者是否立即返回，调用者是不是在等待。 A 调完 B，就在调用处等待（阻塞），直到 B 方法返回才继续执行剩下的代码，这就是阻塞调用。而非阻塞是 A 方法调用 B 方法，B 方法立即返回，A 可以继续执行下面的代码，不会等在这里，不会被该调用阻塞。当某个方法被阻塞了，该方法所在的线程会被挂起，被操作系统的调度器放到阻塞队列，直到 A 等待的事件发生，才从阻塞态转到就绪态。</description>
    </item>
    
  </channel>
</rss>